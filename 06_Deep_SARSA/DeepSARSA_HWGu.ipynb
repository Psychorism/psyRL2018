{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep SARSA : On-policy Prediction & Control Using NN\n",
    "\n",
    "**Approximating** $v_\\pi$ from experience generated using a known policy $\\pi$. It is not represented as a table, but **parameterized functional form with weight vector** $\\mathbf{w} \\in \\mathbb{R}^d$.\n",
    "\n",
    "However, what function approximation cannot do is **augment the state representation with memories of past observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. On-policy Prediction with Approximation\n",
    "\n",
    "### 1.1. The Prediction Objective (VE)\n",
    "\n",
    "By assumption, we have **far more states than weights**, so making one state's estimate more accurate invariably means making others' less accurate. We must specify a state distribution $\\mu(s) \\ge 0, \\sum_s \\mu(s) = 1$, representing how much we care about the error in each state $s$.\n",
    "\n",
    "$$\n",
    "\\text{VE}(w) \\overset{def}{\\equiv} \\sum_{s \\in S} \\mu (s) \\Big[ v_{\\pi} (s) - \\hat{v} (s, w) \\Big] ^2\n",
    "$$\n",
    "\n",
    "### Comparison of estimators\n",
    "\n",
    "1. **Maximum MSE** : $\\max \\mathbb{E}_\\theta \\Big[ ( \\hat{\\eta} - \\eta(\\theta) ) \\Big]^2$\n",
    "\n",
    "$$\n",
    "\\max_{\\theta \\in \\Omega} \\mathbb{E}_\\theta \\Big[ ( \\hat{\\eta}^{*} - \\eta(\\theta))^2 \\Big] = \\min_{\\hat{\\eta}} \\max_{\\theta \\in \\Omega} \\mathbb{E}_\\theta \\Big[ (\\hat{\\eta} - \\eta(\\theta) \\Big]\n",
    "$$\n",
    "\n",
    "2. **Bayesian MSE** : weighted average of **prior density** $\\pi$, a function on $\\Omega$\n",
    "\n",
    "$$\n",
    "r(\\pi, \\hat{\\eta}) = \\int_{\\Omega} \\mathbb{E}_\\theta \\Big[ ( \\hat{\\eta} - \\eta(\\theta) )^2 \\Big] \\pi(\\theta) d \\theta\n",
    "$$\n",
    "\n",
    "**When unbiased** : $\\text{Var} (\\hat{\\eta}^{\\text{UE}})$ minimized : **UMVUE**\n",
    "\n",
    "$$\n",
    "\\text{MSE} (\\hat{\\eta}^{\\text{UE}}, \\theta) = \\mathbb{E}_\\theta \\Big[ (\\hat{\\eta}^{\\text{UE}} - \\eta(\\theta) )^2 \\Big] = \\mathbb{E}_\\theta \\Big[ (\\hat{\\eta}^{\\text{UE}} - \\mathbb{E}_\\theta \\hat{\\eta}^{\\text{UE}} )^2 \\Big] = \\text{Var}_\\theta (\\hat{\\eta}^{\\text{UE}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Stochastic-gradient and Semi-gradient Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient methods (Linear regression cases)\n",
    "\n",
    "**a. Batch gradient descent** : $J_{\\text{train}} = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta (x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "Repeat\n",
    "\n",
    "$\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m (h_\\theta (x^{(i)}) - y^{(i)}) x^{(i)} \\Big(= \\theta_j -  \\alpha  \\frac{\\partial}{\\partial \\theta_j} J_{\\text{train}}(\\theta) \\Big)\n",
    "$\n",
    "\n",
    "for every $j = 0, \\ldots, n$\n",
    "\n",
    "**b. Stochastic gradient descent** : single sample-based\n",
    "\n",
    "$\n",
    "\\text{cost} \\big(\\theta, (x^{(i)}, y^{(i)}) \\big) = \\frac{1}{2} \\big( h_\\theta (x^{(i)}) - y^{(i)} \\big)^2\n",
    "$\n",
    "\n",
    "$J_{\\text{train}} = \\frac{1}{m} \\sum_{i=1}^m \\text{cost} \\big(\\theta, (x^{(i)}, y^{(i)})$\n",
    "\n",
    "1) Randomly shuffle dataset.\n",
    "\n",
    "2) Repeat\n",
    "\n",
    "for $i = 1, \\ldots, m$\n",
    "\n",
    "$\n",
    "\\theta_j := \\theta_j - \\alpha (h_\\theta (x^{(i)}) - y^{(i)}) x^{(i)} \\Big(= \\theta_j -  \\alpha  \\frac{\\partial}{\\partial \\theta_j} \\text{cost} \\big(\\theta, (x^{(i)}, y^{(i)}) \\Big)\n",
    "$\n",
    "\n",
    "for every $j = 0, \\ldots, n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Linear Approximation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof of Convergence of Linear TD(0)\n",
    "\n",
    "General SGD method formula for state-value prediction ($U_t$ : substituted because $v_\\pi (S_t)$ : **unknown**)\n",
    "\n",
    "$$\n",
    "w_{t+1} \\equiv w_t + \\alpha \\Big[ U_t - \\hat{v} (S_t, w_t) \\Big] \\nabla \\hat{v} (S_t, w_t)\n",
    "$$\n",
    "\n",
    "Since in linear methods,\n",
    "\n",
    "$$\n",
    "\\hat{v} (s, w) \\equiv w^T \\mathbf{x} (s) \\equiv \\sum_{i=1}^d w_i x_i (s) \\\\\n",
    "\\nabla \\hat{v} (s, w) = \\mathbf{x} (s)\n",
    "$$\n",
    "\n",
    "thus,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w_{t+1} &\\equiv w_t + \\alpha \\Big[ U_t - \\hat{v} (S_t, w_t) \\Big] \\mathbf{x} (s) \\\\[15pt]\n",
    "&\\equiv w_t + \\alpha \\big( R_{t+1} + \\gamma w_t ^T \\mathbf{x}_{t+1} - w_t^T \\mathbf{x}_t \\big) \\mathbf{x}_t \\\\[15pt]\n",
    "&= w_t + \\alpha \\big( R_{t+1} \\mathbf{x}_t - \\mathbf{x}_t ( \\mathbf{x}_t - \\gamma \\mathbf{x}_{t+1})^T w_t \\big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "When the system has reached **steady state**, for any given $w_t$,\n",
    "\n",
    "$$\n",
    "\\mathbb{E} [w_{t+1} | w_t ] = w_t + \\alpha (b - \\mathbf{A} w_t)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{A} = \\mathbf{X}^T \\mathbf{D} (\\mathbf{I} - \\gamma \\mathbf{P}) \\mathbf{X}$. We have $\\mathbf{D} (\\mathbf{I} - \\gamma \\mathbf{P})$ : positive definite and \n",
    "\n",
    "$$\n",
    "1^T \\mathbf{D} (\\mathbf{I} - \\gamma \\mathbf{P}) = (1 - \\gamma) \\mathbf{\\mu}^T\n",
    "$$\n",
    "\n",
    "where $\\mathbf{\\mu}$ : stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Feature Construction for Linear Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomials\n",
    "\n",
    "$$\n",
    "x_i (s) \\equiv \\prod_{j=1}^k s_k ^{c_{i,j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourier Basis\n",
    "\n",
    "$$\n",
    "x_i (s) \\equiv \\cos (\\pi \\mathbf{s} ^T \\mathbf{c}^i )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radial Basis Functions\n",
    "\n",
    "**RBF**s are natural **generalization of coarse coding** to **continuous-valued features**.\n",
    "\n",
    "$$\n",
    "x_i (s) \\equiv exp \\Big( - \\frac {||s - c_i||^2} {2 \\sigma_i^2} \\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Nonlinear Function Approximation : ANN\n",
    "\n",
    "The most sophisticated ANN and statistical methods all assume a static training set over which multiple passes are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States defined\n",
    "\n",
    "1. **The position** of the terminal relative to the agent\n",
    "\n",
    "2. **The label** of the terminal\n",
    "\n",
    "3. **The positions** of obstacles relative to the agent\n",
    "\n",
    "4. **The label** of the obstacles\n",
    "\n",
    "5. **The speed** of the obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q function updating\n",
    "\n",
    "$$\n",
    "Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\Big(R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1}) -Q(S_t, A_t) \\Big)\n",
    "$$\n",
    "\n",
    "#### Gradient Descent : MSE\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\Big(R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1} ) - Q(S_t, A_t) \\Big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. On-policy Control with Approximation\n",
    "\n",
    "With parametric apporximation of **action-value function** $\\hat{q}(s,a,\\mathbf{w}) \\sim q_{*} (s, a)$ (where $\\mathbf{w} \\in \\mathbb{R}^d$) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Episodic Semi-gradient Control : SARSA\n",
    "\n",
    "$$\n",
    "w_{t+1} \\equiv w_t + \\alpha \\Big[ U_t - \\hat{q} (S_t, A_t, w_t) \\Big] \\nabla \\hat{q} (S_t, A_t, w_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Semi-gradient $n$-step SARSA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
